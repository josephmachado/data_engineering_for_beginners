{
  "hash": "6dc8a76af31e26c2404f33684af9fd9a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 'Data warehouse modeling (Kimball) is based off of 2 types of tables: Fact and dimensions'\nformat:\n  html:\n    toc: true\nexecute:\n  eval: false\n  output: true\njupyter: python3\n---\n\n\n\n\nAs we saw in the previous chapter, Kimball is by far the most commonly used, while companies don't always follow it to a T, facts and dimensions form the basis of most of the data warehouses in the wild.\n\n## Facts represents events that occured & dimensions the entities to which events occur to\n\nA data warehouse is a database that stores your company's historical data. The main types of tables you need to create to power analytics are:\n\n1. **` Dimension`**: Each row in a dimension table represents a business entity that is important to the business. For example, An car parts seller's data warehouse will have a `customer` dimension table, where each row will represent an individual customer. Other examples of dimension tables in a car parts seller's data warehouse would be `supplier` & `part` tables.\n\n2. **` Facts`**: Each row in a fact table represents a business process that occurred. E.g., In our data warehouse, each row in the `orders` fact table will represent an individual order, and each row in the `lineitem` fact table will represent an item sold as part of an order. Each fact row will have a unique identifier; in our case, it's `orderkey` for orders and a combination of `orderkey & linenumber` for lineitem.\n\nA fact table's **` grain (aka granularity, level)`** refers to what a row in a fact table represents. E.g., In our checkout process, we can have two fact tables, one for the order and another for the individual items in the order. The items table will have one row per item purchased, whereas the order table will have one row per order made.\n\n<!-- ![TPC-H data model](./images/lineitem_order_lvl.png){#id .class width=30px height=20px}-->\n\n::: {#0a4e464a .cell execution_count=1}\n``` {.python .cell-code}\n%%sql\nuse prod.db\n```\n:::\n\n\n::: {#f3ac7b48 .cell execution_count=2}\n``` {.python .cell-code}\n%%sql\n-- calculating the totalprice of an order (with orderkey = 1) from it's individual items\nSELECT\n    l_orderkey,\n    round( sum(l_extendedprice * (1 - l_discount) * (1 + l_tax)),\n        2\n    ) AS totalprice\nFROM\n    lineitem\nWHERE\n    l_orderkey = 1\nGROUP BY\n    l_orderkey;\n```\n:::\n\n\n::: {#0d1f489b .cell execution_count=3}\n``` {.python .cell-code}\n%%sql\n-- The totalprice of an order (with orderkey = 1)\nSELECT\n    o_orderkey,\n    o_totalprice\nFROM\n    orders\nWHERE\n    o_orderkey = 1;\n```\n:::\n\n\n**Note:** If you notice the slight difference in the decimal digits, it's due to using a `double` datatype which is an inexact data type.\n\nWe can see how the `lineitem` table can be \"rolled up\" to get the data in the `orders` table. But having just the `orders` table is not sufficient since the `lineitem` table will provide us with individual item details such as discount and quantity details.\n\n### Popular dimension types: Full Snapshot & SCD2 \n\n-  Full snapshot\nIn this type of dimension, the entire dimension table is  re-loaded each run. As the dimension tables are much smaller than the fact table this is usually an acceptable tradeoff. Typically each run would create a new copy while retaining older copy for a certain time period (say 6 months).\n\n- SCD2 \nSCD2 stands for slowly changing dimension type 2. Any change to a column value will be tracked as a new row. \n\nIf your customer makes an address change in SCD2 it will be created as a new table. SCD2 has 3 key columns that allow us to see historical changes \n\n1. valid_from\n2. valid_to \n3. is_current\n\nadd: image showing snapshot dimension and SCD2 dimension model\n\n## One Big Table (OBT) is a fact table left joined with all its dimensions\n\nAs the number of facts and dimensions grow you will notice that most of the queries that are run to get data for the end users use the same tables and the same joins.\n\nIn this scenario the expensive reprocessing of data can be avoided by creating an OBT. In an OBT you left join all the dimensions into a fact table. This big table can then be used to aggregate to different grains as needed for end user reproting.\n\nNote that the OBT should have the same grain as the fact table that it is based on or have the lower grain if you have to join multiple fact tables.\n\nIn our bike-part seller warehouse we can create an OBT by joining all the tables to the lineitem table \n\n```sql\nadd: code\n```\n\n## Summary or pre-aggregated tables are stakeholder-team specific tables built for reporting\n\nStakeholders often require data aggregated at various grains and similar metrics. Creating pre-aggregated or summary tables is creating these report for stakeholders so all they would have to do is select from the table without the need to recompute metrics. This has 2 benefits\n\n1. Same metric formula, as the data engineering will keep the metric definition in the code base, vs each stakeholder using a slightly different version and ending up with different numbers\n2. Avoid unnecessary recomputation as multiple stakeholders can now use the same table\n\nHowever the down side is that the data may not be as fresh as what a stakeholder would get if they just write a query.\n\n## Exercises\n\n1. What are the fact tables in our TPCH data model?\n2. What source tables in TPCH data model would you consider to create a customer dimension table?\n\n## Recommended reading\n\n1. https://www.startdataengineering.com/post/metrics_sot/\n2. https://www.startdataengineering.com/post/n-steps-avoid-messy-dw/\n3. https://www.startdataengineering.com/post/data-lake-warehouse-diff/\n4. https://www.startdataengineering.com/post/what-is-a-data-warehouse/\n\n",
    "supporting": [
      "dw_table_types_files"
    ],
    "filters": [],
    "includes": {}
  }
}