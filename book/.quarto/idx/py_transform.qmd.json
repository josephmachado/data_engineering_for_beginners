{"title":"Python has libraries to tell the data processing engine (Spark, Trino, Duckdb, Polars, etc) what to do","markdown":{"yaml":{"title":"Python has libraries to tell the data processing engine (Spark, Trino, Duckdb, Polars, etc) what to do","format":{"html":{"toc":true}},"execute":{"eval":false,"output":true},"jupyter":"python3"},"headingText":"Read data from CSV file into DataFrame","containsRefs":false,"markdown":"\n\n\nAlmost every data processing systems has a Python library to interact with it. \n\nPyspark\nTrino Python \nSnowflake Python\nDuckdb Python \nPolars Python API\nadd: link\n\nThe main types of data processing libraries are:\n\n1. **`Python standard libraries`**: Python has a strong set of standard libraries for processing data. When using standard libraries, you'll usually be working on Python native data structures (add: link). Some popular ones are [csv](https://docs.python.org/3/library/csv.html), [json](https://docs.python.org/3/library/json.html), [gzip](https://docs.python.org/3/library/gzip.html) etc.\n2. **`Dataframe libraries`**: Libraries like pandas, polars, and Spark enable you to work with tabular data. These libraries use a dataframe (Python's version of a SQL table) and enable you to do everything (and more) you can do with SQL. **Note** that some of these libraries are meant for data that can be processed in memory.\n3. **`Processing data on SQL via Python`**: You can use [database drivers]({{< ref \"/post/python-for-de.md#extract--load-read-and-write-data-to-any-system\" >}}) and write SQL queries to process the data. The benefit of this approach is that you don't need to bring data into Python memory and offload it to the database.\n\n**Note**: When we use systems like `Spark`, `Dask`, `Snowflake`, `BigQuery` to process data, you should note that we interact with them via Python. Data is processed by the external systems.\n\n\n```{python}\nprint(\n    \"################################################################################\"\n)\nprint(\"Use standard python libraries to do the transformations\")\nprint(\n    \"################################################################################\"\n)\n```\n\n```{python}\nimport csv\n\ndata = []\nwith open(\"./sample_data.csv\", \"r\", newline=\"\") as csvfile:\n    reader = csv.DictReader(csvfile)\n    for row in reader:\n        data.append(row)\nprint(data[:2])\n```\n\n```{python}\ndata_unique = []\ncustomer_ids_seen = set()\nfor row in data:\n    if row[\"Customer_ID\"] not in customer_ids_seen:\n        data_unique.append(row)\n        customer_ids_seen.add(row[\"Customer_ID\"])\n    else:\n        print(f'duplicate customer id {row[\"Customer_ID\"]}')\n```\n\n```{python}\nfor row in data_unique:\n    if not row[\"Age\"]:\n        print(f'Customer {row[\"Customer_Name\"]} does not have Age value')\n        row[\"Age\"] = 0\n    if not row[\"Purchase_Amount\"]:\n        row[\"Purchase_Amount\"] = 0.0\n\ndata_cleaned = [\n    row\n    for row in data_unique\n    if int(row[\"Age\"]) <= 100 and float(row[\"Purchase_Amount\"]) <= 1000\n]\n\nfor row in data_cleaned:\n    if row[\"Gender\"] == \"Female\":\n        row[\"Gender\"] = 0\n    elif row[\"Gender\"] == \"Male\":\n        row[\"Gender\"] = 1\n\nfor row in data_cleaned:\n    first_name, last_name = row[\"Customer_Name\"].split(\" \", 1)\n    row[\"First_Name\"] = first_name\n    row[\"Last_Name\"] = last_name\n\nprint(data_cleaned[:3])\n```\n\n```{python}\nfrom collections import defaultdict\ntotal_purchase_by_gender = defaultdict(float)\nfor row in data_cleaned:\n    total_purchase_by_gender[row[\"Gender\"]] += float(row[\"Purchase_Amount\"])\n\nage_groups = {\"18-30\": [], \"31-40\": [], \"41-50\": [], \"51-60\": [], \"61-70\": []}\nfor row in data_cleaned:\n    age = int(row[\"Age\"])\n    if age <= 30:\n        age_groups[\"18-30\"].append(float(row[\"Purchase_Amount\"]))\n    elif age <= 40:\n        age_groups[\"31-40\"].append(float(row[\"Purchase_Amount\"]))\n    elif age <= 50:\n        age_groups[\"41-50\"].append(float(row[\"Purchase_Amount\"]))\n    elif age <= 60:\n        age_groups[\"51-60\"].append(float(row[\"Purchase_Amount\"]))\n    else:\n        age_groups[\"61-70\"].append(float(row[\"Purchase_Amount\"]))\n\naverage_purchase_by_age_group = {\n    group: sum(amounts) / len(amounts) for group, amounts in age_groups.items()\n}\n```\n\n```{python}\nprint(\"Total purchase amount by Gender:\", total_purchase_by_gender)\nprint(\"Average purchase amount by Age group:\", average_purchase_by_age_group)\n```\n\n```{python}\nspark\n```\n\n```{python}\nprint(\n    \"################################################################################\"\n)\nprint(\"Use PySpark DataFrame API to do the transformations\")\nprint(\n    \"################################################################################\"\n)\n```\n\n```{python}\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, coalesce, lit, when, split, sum as spark_sum, avg, regexp_replace\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, DateType\n\nschema = StructType([\n    StructField(\"Customer_ID\", IntegerType(), True),\n    StructField(\"Customer_Name\", StringType(), True),\n    StructField(\"Age\", IntegerType(), True),\n    StructField(\"Gender\", StringType(), True),\n    StructField(\"Purchase_Amount\", FloatType(), True),\n    StructField(\"Purchase_Date\", DateType(), True)\n])\n\ndata = spark.read \\\n    .option(\"header\", \"true\") \\\n    .option(\"inferSchema\", \"false\") \\\n    .schema(schema) \\\n    .csv(\"./sample_data.csv\")\n\n# Question: How do you remove duplicate rows based on customer ID in PySpark?\ndata_unique = data.dropDuplicates()\n\n# Question: How do you handle missing values by replacing them with 0 in PySpark?\ndata_cleaned_missing = data_unique.select(\n    col(\"Customer_ID\"),\n    col(\"Customer_Name\"),\n    coalesce(col(\"Age\"), lit(0)).alias(\"Age\"),\n    col(\"Gender\"),\n    coalesce(col(\"Purchase_Amount\"), lit(0.0)).alias(\"Purchase_Amount\"),\n    col(\"Purchase_Date\")\n)\n\n# Question: How do you remove outliers (e.g., age > 100 or purchase amount > 1000) in PySpark?\ndata_cleaned_outliers = data_cleaned_missing.filter(\n    (col(\"Age\") <= 100) & (col(\"Purchase_Amount\") <= 1000)\n)\n\n# Question: How do you convert the Gender column to a binary format (0 for Female, 1 for Male) in PySpark?\ndata_cleaned_gender = data_cleaned_outliers.withColumn(\n    \"Gender_Binary\",\n    when(col(\"Gender\") == \"Female\", 0).otherwise(1)\n)\n\n# Question: How do you split the Customer_Name column into separate First_Name and Last_Name columns in PySpark?\ndata_cleaned = data_cleaned_gender.select(\n    col(\"Customer_ID\"),\n    split(col(\"Customer_Name\"), \" \").getItem(0).alias(\"First_Name\"),\n    split(col(\"Customer_Name\"), \" \").getItem(1).alias(\"Last_Name\"),\n    col(\"Age\"),\n    col(\"Gender_Binary\"),\n    col(\"Purchase_Amount\"),\n    col(\"Purchase_Date\")\n)\n```\n\n```{python}\n# Question: How do you calculate the total purchase amount by Gender in PySpark?\ntotal_purchase_by_gender = data_cleaned_gender.groupBy(\"Gender_Binary\") \\\n    .agg(spark_sum(\"Purchase_Amount\").alias(\"Total_Purchase_Amount\")) \\\n    .collect()\n```\n\n```{python}\n# Question: How do you calculate the average purchase amount by Age group in PySpark?\naverage_purchase_by_age_group = data_cleaned.withColumn(\n    \"Age_Group\",\n    when((col(\"Age\") >= 18) & (col(\"Age\") <= 30), \"18-30\")\n    .when((col(\"Age\") >= 31) & (col(\"Age\") <= 40), \"31-40\")\n    .when((col(\"Age\") >= 41) & (col(\"Age\") <= 50), \"41-50\")\n    .when((col(\"Age\") >= 51) & (col(\"Age\") <= 60), \"51-60\")\n    .otherwise(\"61-70\")\n).groupBy(\"Age_Group\") \\\n    .agg(avg(\"Purchase_Amount\").alias(\"Average_Purchase_Amount\")) \\\n    .collect()\n```\n\n```{python}\n# Question: How do you print the results for total purchase amount by Gender and average purchase amount by Age group in PySpark?\nprint(\"====================== Results ======================\")\nprint(\"Total purchase amount by Gender:\")\nfor row in total_purchase_by_gender:\n    print(f\"Gender_Binary: {row['Gender_Binary']}, Total_Purchase_Amount: {row['Total_Purchase_Amount']}\")\n\nprint(\"Average purchase amount by Age group:\")\nfor row in average_purchase_by_age_group:\n    print(f\"Age_Group: {row['Age_Group']}, Average_Purchase_Amount: {row['Average_Purchase_Amount']}\")\n```\n\n```{python}\n# Optional: Show DataFrame contents for verification\nprint(\"\\n====================== Data Preview ======================\")\nprint(\"Final cleaned data:\")\ndata_cleaned.show(10)\n```\n\n```{python}\nprint(\"Total purchase by gender:\")\ndata_cleaned_gender.groupBy(\"Gender_Binary\") \\\n    .agg(spark_sum(\"Purchase_Amount\").alias(\"Total_Purchase_Amount\")) \\\n    .show()\n```\n\n```{python}\nprint(\"Average purchase by age group:\")\ndata_cleaned.withColumn(\n    \"Age_Group\",\n    when((col(\"Age\") >= 18) & (col(\"Age\") <= 30), \"18-30\")\n    .when((col(\"Age\") >= 31) & (col(\"Age\") <= 40), \"31-40\")\n    .when((col(\"Age\") >= 41) & (col(\"Age\") <= 50), \"41-50\")\n    .when((col(\"Age\") >= 51) & (col(\"Age\") <= 60), \"51-60\")\n    .otherwise(\"61-70\")\n).groupBy(\"Age_Group\") \\\n    .agg(avg(\"Purchase_Amount\").alias(\"Average_Purchase_Amount\")) \\\n    .show()\n```\n\n","srcMarkdownNoYaml":"\n\n\nAlmost every data processing systems has a Python library to interact with it. \n\nPyspark\nTrino Python \nSnowflake Python\nDuckdb Python \nPolars Python API\nadd: link\n\nThe main types of data processing libraries are:\n\n1. **`Python standard libraries`**: Python has a strong set of standard libraries for processing data. When using standard libraries, you'll usually be working on Python native data structures (add: link). Some popular ones are [csv](https://docs.python.org/3/library/csv.html), [json](https://docs.python.org/3/library/json.html), [gzip](https://docs.python.org/3/library/gzip.html) etc.\n2. **`Dataframe libraries`**: Libraries like pandas, polars, and Spark enable you to work with tabular data. These libraries use a dataframe (Python's version of a SQL table) and enable you to do everything (and more) you can do with SQL. **Note** that some of these libraries are meant for data that can be processed in memory.\n3. **`Processing data on SQL via Python`**: You can use [database drivers]({{< ref \"/post/python-for-de.md#extract--load-read-and-write-data-to-any-system\" >}}) and write SQL queries to process the data. The benefit of this approach is that you don't need to bring data into Python memory and offload it to the database.\n\n**Note**: When we use systems like `Spark`, `Dask`, `Snowflake`, `BigQuery` to process data, you should note that we interact with them via Python. Data is processed by the external systems.\n\n\n```{python}\nprint(\n    \"################################################################################\"\n)\nprint(\"Use standard python libraries to do the transformations\")\nprint(\n    \"################################################################################\"\n)\n```\n\n```{python}\nimport csv\n\ndata = []\nwith open(\"./sample_data.csv\", \"r\", newline=\"\") as csvfile:\n    reader = csv.DictReader(csvfile)\n    for row in reader:\n        data.append(row)\nprint(data[:2])\n```\n\n```{python}\ndata_unique = []\ncustomer_ids_seen = set()\nfor row in data:\n    if row[\"Customer_ID\"] not in customer_ids_seen:\n        data_unique.append(row)\n        customer_ids_seen.add(row[\"Customer_ID\"])\n    else:\n        print(f'duplicate customer id {row[\"Customer_ID\"]}')\n```\n\n```{python}\nfor row in data_unique:\n    if not row[\"Age\"]:\n        print(f'Customer {row[\"Customer_Name\"]} does not have Age value')\n        row[\"Age\"] = 0\n    if not row[\"Purchase_Amount\"]:\n        row[\"Purchase_Amount\"] = 0.0\n\ndata_cleaned = [\n    row\n    for row in data_unique\n    if int(row[\"Age\"]) <= 100 and float(row[\"Purchase_Amount\"]) <= 1000\n]\n\nfor row in data_cleaned:\n    if row[\"Gender\"] == \"Female\":\n        row[\"Gender\"] = 0\n    elif row[\"Gender\"] == \"Male\":\n        row[\"Gender\"] = 1\n\nfor row in data_cleaned:\n    first_name, last_name = row[\"Customer_Name\"].split(\" \", 1)\n    row[\"First_Name\"] = first_name\n    row[\"Last_Name\"] = last_name\n\nprint(data_cleaned[:3])\n```\n\n```{python}\nfrom collections import defaultdict\ntotal_purchase_by_gender = defaultdict(float)\nfor row in data_cleaned:\n    total_purchase_by_gender[row[\"Gender\"]] += float(row[\"Purchase_Amount\"])\n\nage_groups = {\"18-30\": [], \"31-40\": [], \"41-50\": [], \"51-60\": [], \"61-70\": []}\nfor row in data_cleaned:\n    age = int(row[\"Age\"])\n    if age <= 30:\n        age_groups[\"18-30\"].append(float(row[\"Purchase_Amount\"]))\n    elif age <= 40:\n        age_groups[\"31-40\"].append(float(row[\"Purchase_Amount\"]))\n    elif age <= 50:\n        age_groups[\"41-50\"].append(float(row[\"Purchase_Amount\"]))\n    elif age <= 60:\n        age_groups[\"51-60\"].append(float(row[\"Purchase_Amount\"]))\n    else:\n        age_groups[\"61-70\"].append(float(row[\"Purchase_Amount\"]))\n\naverage_purchase_by_age_group = {\n    group: sum(amounts) / len(amounts) for group, amounts in age_groups.items()\n}\n```\n\n```{python}\nprint(\"Total purchase amount by Gender:\", total_purchase_by_gender)\nprint(\"Average purchase amount by Age group:\", average_purchase_by_age_group)\n```\n\n```{python}\nspark\n```\n\n```{python}\nprint(\n    \"################################################################################\"\n)\nprint(\"Use PySpark DataFrame API to do the transformations\")\nprint(\n    \"################################################################################\"\n)\n```\n\n```{python}\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, coalesce, lit, when, split, sum as spark_sum, avg, regexp_replace\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, DateType\n\nschema = StructType([\n    StructField(\"Customer_ID\", IntegerType(), True),\n    StructField(\"Customer_Name\", StringType(), True),\n    StructField(\"Age\", IntegerType(), True),\n    StructField(\"Gender\", StringType(), True),\n    StructField(\"Purchase_Amount\", FloatType(), True),\n    StructField(\"Purchase_Date\", DateType(), True)\n])\n\n# Read data from CSV file into DataFrame\ndata = spark.read \\\n    .option(\"header\", \"true\") \\\n    .option(\"inferSchema\", \"false\") \\\n    .schema(schema) \\\n    .csv(\"./sample_data.csv\")\n\n# Question: How do you remove duplicate rows based on customer ID in PySpark?\ndata_unique = data.dropDuplicates()\n\n# Question: How do you handle missing values by replacing them with 0 in PySpark?\ndata_cleaned_missing = data_unique.select(\n    col(\"Customer_ID\"),\n    col(\"Customer_Name\"),\n    coalesce(col(\"Age\"), lit(0)).alias(\"Age\"),\n    col(\"Gender\"),\n    coalesce(col(\"Purchase_Amount\"), lit(0.0)).alias(\"Purchase_Amount\"),\n    col(\"Purchase_Date\")\n)\n\n# Question: How do you remove outliers (e.g., age > 100 or purchase amount > 1000) in PySpark?\ndata_cleaned_outliers = data_cleaned_missing.filter(\n    (col(\"Age\") <= 100) & (col(\"Purchase_Amount\") <= 1000)\n)\n\n# Question: How do you convert the Gender column to a binary format (0 for Female, 1 for Male) in PySpark?\ndata_cleaned_gender = data_cleaned_outliers.withColumn(\n    \"Gender_Binary\",\n    when(col(\"Gender\") == \"Female\", 0).otherwise(1)\n)\n\n# Question: How do you split the Customer_Name column into separate First_Name and Last_Name columns in PySpark?\ndata_cleaned = data_cleaned_gender.select(\n    col(\"Customer_ID\"),\n    split(col(\"Customer_Name\"), \" \").getItem(0).alias(\"First_Name\"),\n    split(col(\"Customer_Name\"), \" \").getItem(1).alias(\"Last_Name\"),\n    col(\"Age\"),\n    col(\"Gender_Binary\"),\n    col(\"Purchase_Amount\"),\n    col(\"Purchase_Date\")\n)\n```\n\n```{python}\n# Question: How do you calculate the total purchase amount by Gender in PySpark?\ntotal_purchase_by_gender = data_cleaned_gender.groupBy(\"Gender_Binary\") \\\n    .agg(spark_sum(\"Purchase_Amount\").alias(\"Total_Purchase_Amount\")) \\\n    .collect()\n```\n\n```{python}\n# Question: How do you calculate the average purchase amount by Age group in PySpark?\naverage_purchase_by_age_group = data_cleaned.withColumn(\n    \"Age_Group\",\n    when((col(\"Age\") >= 18) & (col(\"Age\") <= 30), \"18-30\")\n    .when((col(\"Age\") >= 31) & (col(\"Age\") <= 40), \"31-40\")\n    .when((col(\"Age\") >= 41) & (col(\"Age\") <= 50), \"41-50\")\n    .when((col(\"Age\") >= 51) & (col(\"Age\") <= 60), \"51-60\")\n    .otherwise(\"61-70\")\n).groupBy(\"Age_Group\") \\\n    .agg(avg(\"Purchase_Amount\").alias(\"Average_Purchase_Amount\")) \\\n    .collect()\n```\n\n```{python}\n# Question: How do you print the results for total purchase amount by Gender and average purchase amount by Age group in PySpark?\nprint(\"====================== Results ======================\")\nprint(\"Total purchase amount by Gender:\")\nfor row in total_purchase_by_gender:\n    print(f\"Gender_Binary: {row['Gender_Binary']}, Total_Purchase_Amount: {row['Total_Purchase_Amount']}\")\n\nprint(\"Average purchase amount by Age group:\")\nfor row in average_purchase_by_age_group:\n    print(f\"Age_Group: {row['Age_Group']}, Average_Purchase_Amount: {row['Average_Purchase_Amount']}\")\n```\n\n```{python}\n# Optional: Show DataFrame contents for verification\nprint(\"\\n====================== Data Preview ======================\")\nprint(\"Final cleaned data:\")\ndata_cleaned.show(10)\n```\n\n```{python}\nprint(\"Total purchase by gender:\")\ndata_cleaned_gender.groupBy(\"Gender_Binary\") \\\n    .agg(spark_sum(\"Purchase_Amount\").alias(\"Total_Purchase_Amount\")) \\\n    .show()\n```\n\n```{python}\nprint(\"Average purchase by age group:\")\ndata_cleaned.withColumn(\n    \"Age_Group\",\n    when((col(\"Age\") >= 18) & (col(\"Age\") <= 30), \"18-30\")\n    .when((col(\"Age\") >= 31) & (col(\"Age\") <= 40), \"31-40\")\n    .when((col(\"Age\") >= 41) & (col(\"Age\") <= 50), \"41-50\")\n    .when((col(\"Age\") >= 51) & (col(\"Age\") <= 60), \"51-60\")\n    .otherwise(\"61-70\")\n).groupBy(\"Age_Group\") \\\n    .agg(avg(\"Purchase_Amount\").alias(\"Average_Purchase_Amount\")) \\\n    .show()\n```\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":false,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc-depth":4,"toc":true,"output-file":"py_transform.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.32","bibliography":["references.bib"],"theme":"cosmo","title":"Python has libraries to tell the data processing engine (Spark, Trino, Duckdb, Polars, etc) what to do","jupyter":"python3"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":false,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"py_transform.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"block-headings":true,"bibliography":["references.bib"],"documentclass":"scrreprt","title":"Python has libraries to tell the data processing engine (Spark, Trino, Duckdb, Polars, etc) what to do","jupyter":"python3"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}