{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c46f75dc-a92c-4c03-8d35-9d11184d412c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Python has libraries to tell the data processing engine (Spark, Trino, Duckdb, Polars, etc) what to do\"\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "execute:\n",
    "    eval: false\n",
    "    output: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54800412-686b-407d-bb2d-de872b3ffb57",
   "metadata": {},
   "source": [
    "Almost every data processing systems has a Python library to interact with it. \n",
    "\n",
    "Pyspark\n",
    "Trino Python \n",
    "Snowflake Python\n",
    "Duckdb Python \n",
    "Polars Python API\n",
    "add: link\n",
    "\n",
    "The main types of data processing libraries are:\n",
    "\n",
    "1. **`Python standard libraries`**: Python has a strong set of standard libraries for processing data. When using standard libraries, you'll usually be working on Python native data structures (add: link). Some popular ones are [csv](https://docs.python.org/3/library/csv.html), [json](https://docs.python.org/3/library/json.html), [gzip](https://docs.python.org/3/library/gzip.html) etc.\n",
    "2. **`Dataframe libraries`**: Libraries like pandas, polars, and Spark enable you to work with tabular data. These libraries use a dataframe (Python's version of a SQL table) and enable you to do everything (and more) you can do with SQL. **Note** that some of these libraries are meant for data that can be processed in memory.\n",
    "3. **`Processing data on SQL via Python`**: You can use [database drivers]({{< ref \"/post/python-for-de.md#extract--load-read-and-write-data-to-any-system\" >}}) and write SQL queries to process the data. The benefit of this approach is that you don't need to bring data into Python memory and offload it to the database.\n",
    "\n",
    "**Note**: When we use systems like `Spark`, `Dask`, `Snowflake`, `BigQuery` to process data, you should note that we interact with them via Python. Data is processed by the external systems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abbd4b6-78be-4ef8-888a-f84ea0aed6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "Use standard python libraries to do the transformations\n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"################################################################################\"\n",
    ")\n",
    "print(\"Use standard python libraries to do the transformations\")\n",
    "print(\n",
    "    \"################################################################################\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6176cb80-fba1-432b-8134-4de51a2988a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Customer_ID': '1', 'Customer_Name': 'Henry Jones', 'Age': '32', 'Gender': 'Male', 'Purchase_Amount': '1080000.66', 'Purchase_Date': '2023-08-15'}, {'Customer_ID': '2', 'Customer_Name': 'Emma Rodriguez', 'Age': '24', 'Gender': 'Male', 'Purchase_Amount': '62.4', 'Purchase_Date': '2024-04-16'}]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "data = []\n",
    "with open(\"./sample_data.csv\", \"r\", newline=\"\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "print(data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be35c400-5b20-4f90-8422-34ce7e2e1315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate customer id 84\n",
      "duplicate customer id 85\n",
      "duplicate customer id 86\n",
      "duplicate customer id 87\n",
      "duplicate customer id 88\n",
      "duplicate customer id 89\n",
      "duplicate customer id 90\n",
      "duplicate customer id 91\n"
     ]
    }
   ],
   "source": [
    "data_unique = []\n",
    "customer_ids_seen = set()\n",
    "for row in data:\n",
    "    if row[\"Customer_ID\"] not in customer_ids_seen:\n",
    "        data_unique.append(row)\n",
    "        customer_ids_seen.add(row[\"Customer_ID\"])\n",
    "    else:\n",
    "        print(f'duplicate customer id {row[\"Customer_ID\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aa329b9-3519-4188-a178-71f0a0944ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Alice Johnson does not have Age value\n",
      "Customer Jack Garcia does not have Age value\n",
      "[{'Customer_ID': '2', 'Customer_Name': 'Emma Rodriguez', 'Age': '24', 'Gender': 1, 'Purchase_Amount': '62.4', 'Purchase_Date': '2024-04-16', 'First_Name': 'Emma', 'Last_Name': 'Rodriguez'}, {'Customer_ID': '3', 'Customer_Name': 'Frank Martinez', 'Age': '20', 'Gender': 0, 'Purchase_Amount': '443.47', 'Purchase_Date': '2024-05-16', 'First_Name': 'Frank', 'Last_Name': 'Martinez'}, {'Customer_ID': '4', 'Customer_Name': 'Alice Rodriguez', 'Age': '62', 'Gender': 0, 'Purchase_Amount': '729.69', 'Purchase_Date': '2024-01-05', 'First_Name': 'Alice', 'Last_Name': 'Rodriguez'}]\n"
     ]
    }
   ],
   "source": [
    "for row in data_unique:\n",
    "    if not row[\"Age\"]:\n",
    "        print(f'Customer {row[\"Customer_Name\"]} does not have Age value')\n",
    "        row[\"Age\"] = 0\n",
    "    if not row[\"Purchase_Amount\"]:\n",
    "        row[\"Purchase_Amount\"] = 0.0\n",
    "\n",
    "data_cleaned = [\n",
    "    row\n",
    "    for row in data_unique\n",
    "    if int(row[\"Age\"]) <= 100 and float(row[\"Purchase_Amount\"]) <= 1000\n",
    "]\n",
    "\n",
    "for row in data_cleaned:\n",
    "    if row[\"Gender\"] == \"Female\":\n",
    "        row[\"Gender\"] = 0\n",
    "    elif row[\"Gender\"] == \"Male\":\n",
    "        row[\"Gender\"] = 1\n",
    "\n",
    "for row in data_cleaned:\n",
    "    first_name, last_name = row[\"Customer_Name\"].split(\" \", 1)\n",
    "    row[\"First_Name\"] = first_name\n",
    "    row[\"Last_Name\"] = last_name\n",
    "\n",
    "print(data_cleaned[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44ffc222-1234-4509-aaba-f9ee1888edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "total_purchase_by_gender = defaultdict(float)\n",
    "for row in data_cleaned:\n",
    "    total_purchase_by_gender[row[\"Gender\"]] += float(row[\"Purchase_Amount\"])\n",
    "\n",
    "age_groups = {\"18-30\": [], \"31-40\": [], \"41-50\": [], \"51-60\": [], \"61-70\": []}\n",
    "for row in data_cleaned:\n",
    "    age = int(row[\"Age\"])\n",
    "    if age <= 30:\n",
    "        age_groups[\"18-30\"].append(float(row[\"Purchase_Amount\"]))\n",
    "    elif age <= 40:\n",
    "        age_groups[\"31-40\"].append(float(row[\"Purchase_Amount\"]))\n",
    "    elif age <= 50:\n",
    "        age_groups[\"41-50\"].append(float(row[\"Purchase_Amount\"]))\n",
    "    elif age <= 60:\n",
    "        age_groups[\"51-60\"].append(float(row[\"Purchase_Amount\"]))\n",
    "    else:\n",
    "        age_groups[\"61-70\"].append(float(row[\"Purchase_Amount\"]))\n",
    "\n",
    "average_purchase_by_age_group = {\n",
    "    group: sum(amounts) / len(amounts) for group, amounts in age_groups.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f475c2-5980-45c9-9865-930e374e3c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total purchase amount by Gender: defaultdict(<class 'float'>, {1: 24599.890000000003, 0: 28215.780000000002})\n",
      "Average purchase amount by Age group: {'18-30': 567.9048387096775, '31-40': 555.2423529411764, '41-50': 493.946, '51-60': 494.51882352941175, '61-70': 534.6971428571428}\n"
     ]
    }
   ],
   "source": [
    "print(\"Total purchase amount by Gender:\", total_purchase_by_gender)\n",
    "print(\"Average purchase amount by Age group:\", average_purchase_by_age_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2141cba2-057d-4c41-b4b4-2d2b29f5b5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://d1189b1a6ac0:4050\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7156fffc1810>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7fabd6d-88bf-42d5-860c-38ccf32c6d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "Use PySpark DataFrame API to do the transformations\n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"################################################################################\"\n",
    ")\n",
    "print(\"Use PySpark DataFrame API to do the transformations\")\n",
    "print(\n",
    "    \"################################################################################\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5d5dad4-77e4-41ac-9845-82c875c5c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, coalesce, lit, when, split, sum as spark_sum, avg, regexp_replace\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, DateType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"Customer_ID\", IntegerType(), True),\n",
    "    StructField(\"Customer_Name\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"Gender\", StringType(), True),\n",
    "    StructField(\"Purchase_Amount\", FloatType(), True),\n",
    "    StructField(\"Purchase_Date\", DateType(), True)\n",
    "])\n",
    "\n",
    "# Read data from CSV file into DataFrame\n",
    "data = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"false\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv(\"./sample_data.csv\")\n",
    "\n",
    "# Question: How do you remove duplicate rows based on customer ID in PySpark?\n",
    "data_unique = data.dropDuplicates()\n",
    "\n",
    "# Question: How do you handle missing values by replacing them with 0 in PySpark?\n",
    "data_cleaned_missing = data_unique.select(\n",
    "    col(\"Customer_ID\"),\n",
    "    col(\"Customer_Name\"),\n",
    "    coalesce(col(\"Age\"), lit(0)).alias(\"Age\"),\n",
    "    col(\"Gender\"),\n",
    "    coalesce(col(\"Purchase_Amount\"), lit(0.0)).alias(\"Purchase_Amount\"),\n",
    "    col(\"Purchase_Date\")\n",
    ")\n",
    "\n",
    "# Question: How do you remove outliers (e.g., age > 100 or purchase amount > 1000) in PySpark?\n",
    "data_cleaned_outliers = data_cleaned_missing.filter(\n",
    "    (col(\"Age\") <= 100) & (col(\"Purchase_Amount\") <= 1000)\n",
    ")\n",
    "\n",
    "# Question: How do you convert the Gender column to a binary format (0 for Female, 1 for Male) in PySpark?\n",
    "data_cleaned_gender = data_cleaned_outliers.withColumn(\n",
    "    \"Gender_Binary\",\n",
    "    when(col(\"Gender\") == \"Female\", 0).otherwise(1)\n",
    ")\n",
    "\n",
    "# Question: How do you split the Customer_Name column into separate First_Name and Last_Name columns in PySpark?\n",
    "data_cleaned = data_cleaned_gender.select(\n",
    "    col(\"Customer_ID\"),\n",
    "    split(col(\"Customer_Name\"), \" \").getItem(0).alias(\"First_Name\"),\n",
    "    split(col(\"Customer_Name\"), \" \").getItem(1).alias(\"Last_Name\"),\n",
    "    col(\"Age\"),\n",
    "    col(\"Gender_Binary\"),\n",
    "    col(\"Purchase_Amount\"),\n",
    "    col(\"Purchase_Date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bb0b042-4b75-41dc-b70a-56075bed3552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: How do you calculate the total purchase amount by Gender in PySpark?\n",
    "total_purchase_by_gender = data_cleaned_gender.groupBy(\"Gender_Binary\") \\\n",
    "    .agg(spark_sum(\"Purchase_Amount\").alias(\"Total_Purchase_Amount\")) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b74b2b89-655d-47bf-b1fe-63bd1a14480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: How do you calculate the average purchase amount by Age group in PySpark?\n",
    "average_purchase_by_age_group = data_cleaned.withColumn(\n",
    "    \"Age_Group\",\n",
    "    when((col(\"Age\") >= 18) & (col(\"Age\") <= 30), \"18-30\")\n",
    "    .when((col(\"Age\") >= 31) & (col(\"Age\") <= 40), \"31-40\")\n",
    "    .when((col(\"Age\") >= 41) & (col(\"Age\") <= 50), \"41-50\")\n",
    "    .when((col(\"Age\") >= 51) & (col(\"Age\") <= 60), \"51-60\")\n",
    "    .otherwise(\"61-70\")\n",
    ").groupBy(\"Age_Group\") \\\n",
    "    .agg(avg(\"Purchase_Amount\").alias(\"Average_Purchase_Amount\")) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f39612a-c3e4-4f51-bf16-d70300138ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Results ======================\n",
      "Total purchase amount by Gender:\n",
      "Gender_Binary: 1, Total_Purchase_Amount: 24599.89005279541\n",
      "Gender_Binary: 0, Total_Purchase_Amount: 28215.77996635437\n",
      "Average purchase amount by Age group:\n",
      "Age_Group: 18-30, Average_Purchase_Amount: 570.8131050899111\n",
      "Age_Group: 41-50, Average_Purchase_Amount: 493.946000289917\n",
      "Age_Group: 31-40, Average_Purchase_Amount: 555.2423526539523\n",
      "Age_Group: 51-60, Average_Purchase_Amount: 494.51882250168745\n",
      "Age_Group: 61-70, Average_Purchase_Amount: 533.576874256134\n"
     ]
    }
   ],
   "source": [
    "# Question: How do you print the results for total purchase amount by Gender and average purchase amount by Age group in PySpark?\n",
    "print(\"====================== Results ======================\")\n",
    "print(\"Total purchase amount by Gender:\")\n",
    "for row in total_purchase_by_gender:\n",
    "    print(f\"Gender_Binary: {row['Gender_Binary']}, Total_Purchase_Amount: {row['Total_Purchase_Amount']}\")\n",
    "\n",
    "print(\"Average purchase amount by Age group:\")\n",
    "for row in average_purchase_by_age_group:\n",
    "    print(f\"Age_Group: {row['Age_Group']}, Average_Purchase_Amount: {row['Average_Purchase_Amount']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbe02e04-d17e-4828-84ef-6a5c80fdabca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================== Data Preview ======================\n",
      "Final cleaned data:\n",
      "+-----------+----------+---------+---+-------------+------------------+-------------+\n",
      "|Customer_ID|First_Name|Last_Name|Age|Gender_Binary|   Purchase_Amount|Purchase_Date|\n",
      "+-----------+----------+---------+---+-------------+------------------+-------------+\n",
      "|         35|     Grace| Williams| 58|            1|139.00999450683594|   2024-04-23|\n",
      "|         93|       Bob|Rodriguez| 26|            1| 891.4600219726562|   2024-01-22|\n",
      "|         58|     Alice|    Jones| 50|            1| 397.8900146484375|   2023-10-04|\n",
      "|         97|       Ivy|    Brown| 21|            1|465.45001220703125|   2023-09-06|\n",
      "|         25|     David|  Johnson| 41|            0| 964.0399780273438|   2023-12-30|\n",
      "|         76|     David|Rodriguez| 23|            1| 212.2899932861328|   2024-03-16|\n",
      "|         33|     Grace|Rodriguez| 43|            1| 366.4200134277344|   2023-07-30|\n",
      "|         72|     Frank|   Miller| 66|            0| 932.3599853515625|   2024-02-19|\n",
      "|         18|      Jack| Martinez| 64|            0| 831.7999877929688|   2023-11-07|\n",
      "|         83|     Alice| Martinez| 41|            0| 185.8300018310547|   2024-02-20|\n",
      "+-----------+----------+---------+---+-------------+------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optional: Show DataFrame contents for verification\n",
    "print(\"\\n====================== Data Preview ======================\")\n",
    "print(\"Final cleaned data:\")\n",
    "data_cleaned.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d630bcfb-572f-426b-923a-3a7de0998e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total purchase by gender:\n",
      "+-------------+---------------------+\n",
      "|Gender_Binary|Total_Purchase_Amount|\n",
      "+-------------+---------------------+\n",
      "|            1|    24599.89005279541|\n",
      "|            0|    28215.77996635437|\n",
      "+-------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Total purchase by gender:\")\n",
    "data_cleaned_gender.groupBy(\"Gender_Binary\") \\\n",
    "    .agg(spark_sum(\"Purchase_Amount\").alias(\"Total_Purchase_Amount\")) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a18bd478-dc31-48cd-a5d4-131c5b58ca30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average purchase by age group:\n",
      "+---------+-----------------------+\n",
      "|Age_Group|Average_Purchase_Amount|\n",
      "+---------+-----------------------+\n",
      "|    18-30|      570.8131050899111|\n",
      "|    41-50|       493.946000289917|\n",
      "|    31-40|      555.2423526539523|\n",
      "|    51-60|     494.51882250168745|\n",
      "|    61-70|       533.576874256134|\n",
      "+---------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Average purchase by age group:\")\n",
    "data_cleaned.withColumn(\n",
    "    \"Age_Group\",\n",
    "    when((col(\"Age\") >= 18) & (col(\"Age\") <= 30), \"18-30\")\n",
    "    .when((col(\"Age\") >= 31) & (col(\"Age\") <= 40), \"31-40\")\n",
    "    .when((col(\"Age\") >= 41) & (col(\"Age\") <= 50), \"41-50\")\n",
    "    .when((col(\"Age\") >= 51) & (col(\"Age\") <= 60), \"51-60\")\n",
    "    .otherwise(\"61-70\")\n",
    ").groupBy(\"Age_Group\") \\\n",
    "    .agg(avg(\"Purchase_Amount\").alias(\"Average_Purchase_Amount\")) \\\n",
    "    .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
